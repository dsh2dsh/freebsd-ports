diff --git config/config.go config/config.go
index 6c56cc3..f31572f 100644
--- config/config.go
+++ config/config.go
@@ -98,6 +98,7 @@ type SendOptions struct {
 	Saved            bool `yaml:"saved,optional,default=false"`
 
 	BandwidthLimit *BandwidthLimit `yaml:"bandwidth_limit,optional,fromdefaults"`
+	ExecPipe       [][]string      `yaml:"execpipe,optional"`
 }
 
 type RecvOptions struct {
@@ -111,6 +112,8 @@ type RecvOptions struct {
 	BandwidthLimit *BandwidthLimit `yaml:"bandwidth_limit,optional,fromdefaults"`
 
 	Placeholder *PlaceholderRecvOptions `yaml:"placeholder,fromdefaults"`
+
+	ExecPipe [][]string `yaml:"execpipe,optional"`
 }
 
 var _ yaml.Unmarshaler = &datasizeunit.Bits{}
@@ -146,9 +149,10 @@ type PlaceholderRecvOptions struct {
 
 type PushJob struct {
 	ActiveJob    `yaml:",inline"`
-	Snapshotting SnapshottingEnum  `yaml:"snapshotting"`
-	Filesystems  FilesystemsFilter `yaml:"filesystems"`
-	Send         *SendOptions      `yaml:"send,fromdefaults,optional"`
+	Interval     *PositiveDurationOrManual `yaml:"interval,optional"`
+	Snapshotting SnapshottingEnum          `yaml:"snapshotting"`
+	Filesystems  FilesystemsFilter         `yaml:"filesystems"`
+	Send         *SendOptions              `yaml:"send,fromdefaults,optional"`
 }
 
 func (j *PushJob) GetFilesystems() FilesystemsFilter { return j.Filesystems }
@@ -421,6 +425,14 @@ type LoggingOutletCommon struct {
 	Format string `yaml:"format"`
 }
 
+type FileLoggingOutlet struct {
+	LoggingOutletCommon `yaml:",inline"`
+	FileName            string `yaml:"filename"`
+	Time                bool   `yaml:"time,default=true"`
+	LogLevel            bool   `yaml:"log_level,default=true"`
+	Template            string `yaml:"template"`
+}
+
 type StdoutLoggingOutlet struct {
 	LoggingOutletCommon `yaml:",inline"`
 	Time                bool `yaml:"time,default=true"`
@@ -582,6 +594,7 @@ func (t *SnapshottingEnum) UnmarshalYAML(u func(interface{}, bool) error) (err e
 
 func (t *LoggingOutletEnum) UnmarshalYAML(u func(interface{}, bool) error) (err error) {
 	t.Ret, err = enumUnmarshal(u, map[string]interface{}{
+		"file":   &FileLoggingOutlet{},
 		"stdout": &StdoutLoggingOutlet{},
 		"syslog": &SyslogLoggingOutlet{},
 		"tcp":    &TCPLoggingOutlet{},
@@ -665,7 +678,6 @@ var ConfigFileDefaultLocations = []string{
 }
 
 func ParseConfig(path string) (i *Config, err error) {
-
 	if path == "" {
 		// Try default locations
 		for _, l := range ConfigFileDefaultLocations {
diff --git daemon/filters/fsmapfilter.go daemon/filters/fsmapfilter.go
index b28da20..eb9a92e 100644
--- daemon/filters/fsmapfilter.go
+++ daemon/filters/fsmapfilter.go
@@ -2,6 +2,7 @@ package filters
 
 import (
 	"fmt"
+	"path/filepath"
 	"strings"
 
 	"github.com/pkg/errors"
@@ -24,6 +25,19 @@ type datasetMapFilterEntry struct {
 	// we have to convert it to the desired rep dynamically
 	mapping      string
 	subtreeMatch bool
+
+	// subtreePattern contains a shell pattern for checking is a subtree matching
+	// this definition or not. See pattern syntax in [filepath.Match].
+	subtreePattern string
+}
+
+func (e datasetMapFilterEntry) HasPattern() bool {
+	return e.subtreePattern != ""
+}
+
+func (e datasetMapFilterEntry) Match(path *zfs.DatasetPath) (bool, error) {
+	fullPattern := filepath.Join(e.path.ToString(), e.subtreePattern)
+	return filepath.Match(fullPattern, path.ToString())
 }
 
 func NewDatasetMapFilter(capacity int, filterMode bool) *DatasetMapFilter {
@@ -43,28 +57,33 @@ func (m *DatasetMapFilter) Add(pathPattern, mapping string) (err error) {
 
 	// assert path glob adheres to spec
 	const SUBTREE_PATTERN string = "<"
-	patternCount := strings.Count(pathPattern, SUBTREE_PATTERN)
-	switch {
-	case patternCount > 1:
-	case patternCount == 1 && !strings.HasSuffix(pathPattern, SUBTREE_PATTERN):
-		err = fmt.Errorf("pattern invalid: only one '<' at end of string allowed")
-		return
+	pathStr, pattern, found := strings.Cut(pathPattern, SUBTREE_PATTERN)
+
+	if pattern != "" {
+		if strings.Contains(pattern, SUBTREE_PATTERN) {
+			return fmt.Errorf(
+				"invalid shell pattern %q in path pattern %q: '<' not allowed in shell patterns",
+				pattern, pathPattern)
+		}
+		if _, err := filepath.Match(pattern, ""); err != nil {
+			return fmt.Errorf(
+				"invalid shell pattern %q in %q: %w", pattern, pathPattern, err)
+		}
 	}
 
-	pathStr := strings.TrimSuffix(pathPattern, SUBTREE_PATTERN)
 	path, err := zfs.NewDatasetPath(pathStr)
 	if err != nil {
 		return fmt.Errorf("pattern is not a dataset path: %s", err)
 	}
 
 	entry := datasetMapFilterEntry{
-		path:         path,
-		mapping:      mapping,
-		subtreeMatch: patternCount > 0,
+		path:           path,
+		mapping:        mapping,
+		subtreeMatch:   found,
+		subtreePattern: pattern,
 	}
 	m.entries = append(m.entries, entry)
 	return
-
 }
 
 // find the most specific prefix mapping we have
@@ -155,9 +174,17 @@ func (m DatasetMapFilter) Filter(p *zfs.DatasetPath) (pass bool, err error) {
 		pass = false
 		return
 	}
+
 	me := m.entries[mi]
-	pass, err = m.parseDatasetFilterResult(me.mapping)
-	return
+	if me.HasPattern() {
+		if matched, err := me.Match(p); err != nil {
+			return false, err
+		} else if !matched {
+			return false, nil
+		}
+	}
+
+	return m.parseDatasetFilterResult(me.mapping)
 }
 
 func (m DatasetMapFilter) UserSpecifiedDatasets() (datasets zfs.UserSpecifiedDatasetsSet) {
diff --git daemon/filters/fsmapfilter_test.go daemon/filters/fsmapfilter_test.go
index eccd59d..9bc58b5 100644
--- daemon/filters/fsmapfilter_test.go
+++ daemon/filters/fsmapfilter_test.go
@@ -54,6 +54,22 @@ func TestDatasetMapFilter(t *testing.T) {
 				"tank/home/bob/downloads": false,
 			},
 		},
+		{
+			name: "with shell patterns",
+			filter: map[string]string{
+				"tank/home</*/foo": "ok",
+				"tank/home/mark<":  "!",
+			},
+			checkPass: map[string]bool{
+				"tank/home":              false,
+				"tank/home/bob":          false,
+				"tank/home/bob/foo":      true,
+				"tank/home/alice/foo":    true,
+				"tank/home/john/foo/bar": false,
+				"tank/home/john/bar":     false,
+				"tank/home/mark/foo":     false,
+			},
+		},
 	}
 
 	for tc := range tcs {
diff --git daemon/job/active.go daemon/job/active.go
index b857aea..1e3e62d 100644
--- daemon/job/active.go
+++ daemon/job/active.go
@@ -102,6 +102,7 @@ type modePush struct {
 	senderConfig  *endpoint.SenderConfig
 	plannerPolicy *logic.PlannerPolicy
 	snapper       snapper.Snapper
+	interval      *config.PositiveDurationOrManual
 }
 
 func (m *modePush) ConnectEndpoints(ctx context.Context, connecter transport.Connecter) {
@@ -132,8 +133,32 @@ func (m *modePush) Type() Type { return TypePush }
 
 func (m *modePush) PlannerPolicy() logic.PlannerPolicy { return *m.plannerPolicy }
 
-func (m *modePush) RunPeriodic(ctx context.Context, wakeUpCommon chan<- struct{}) {
-	m.snapper.Run(ctx, wakeUpCommon)
+func (m *modePush) RunPeriodic(
+	ctx context.Context, wakeUpCommon chan<- struct{},
+) {
+	if m.interval == nil {
+		m.snapper.Run(ctx, wakeUpCommon)
+		return
+	}
+
+	t := time.NewTicker(m.interval.Interval)
+	defer t.Stop()
+
+	for {
+		select {
+		case <-t.C:
+			select {
+			case wakeUpCommon <- struct{}{}:
+			default:
+				GetLogger(ctx).
+					WithField("push_interval", m.interval).
+					Warn("push job took longer than push interval")
+				wakeUpCommon <- struct{}{} // block anyways, to queue up the wakeup
+			}
+		case <-ctx.Done():
+			return
+		}
+	}
 }
 
 func (m *modePush) SnapperReport() *snapper.Report {
@@ -153,6 +178,10 @@ func modePushFromConfig(g *config.Global, in *config.PushJob, jobID endpoint.Job
 	m := &modePush{}
 	var err error
 
+	if _, ok := in.Snapshotting.Ret.(*config.SnapshottingManual); ok {
+		m.interval = in.Interval
+	}
+
 	m.senderConfig, err = buildSenderConfig(in, jobID)
 	if err != nil {
 		return nil, errors.Wrap(err, "sender config")
diff --git daemon/job/build_jobs.go daemon/job/build_jobs.go
index be630e9..dc2de92 100644
--- daemon/job/build_jobs.go
+++ daemon/job/build_jobs.go
@@ -24,21 +24,6 @@ func JobsFromConfig(c *config.Config, parseFlags config.ParseFlags) ([]Job, erro
 		js[i] = j
 	}
 
-	// receiving-side root filesystems must not overlap
-	{
-		rfss := make([]string, 0, len(js))
-		for _, j := range js {
-			jrfs, ok := j.OwnedDatasetSubtreeRoot()
-			if !ok {
-				continue
-			}
-			rfss = append(rfss, jrfs.ToString())
-		}
-		if err := validateReceivingSidesDoNotOverlap(rfss); err != nil {
-			return nil, err
-		}
-	}
-
 	return js, nil
 }
 
diff --git daemon/job/build_jobs_sendrecvoptions.go daemon/job/build_jobs_sendrecvoptions.go
index c403acc..90a608a 100644
--- daemon/job/build_jobs_sendrecvoptions.go
+++ daemon/job/build_jobs_sendrecvoptions.go
@@ -41,6 +41,7 @@ func buildSenderConfig(in SendingJobConfig, jobID endpoint.JobID) (*endpoint.Sen
 		SendSaved:            sendOpts.Saved,
 
 		BandwidthLimit: bwlim,
+		ExecPipe:       sendOpts.ExecPipe,
 	}
 
 	if err := sc.Validate(); err != nil {
@@ -93,7 +94,9 @@ func buildReceiverConfig(in ReceivingJobConfig, jobID endpoint.JobID) (rc endpoi
 		BandwidthLimit: bwlim,
 
 		PlaceholderEncryption: placeholderEncryption,
+		ExecPipe:              recvOpts.ExecPipe,
 	}
+
 	if err := rc.Validate(); err != nil {
 		return rc, errors.Wrap(err, "cannot build receiver config")
 	}
diff --git daemon/logging/build_logging.go daemon/logging/build_logging.go
index 0aff33e..d56e3d9 100644
--- daemon/logging/build_logging.go
+++ daemon/logging/build_logging.go
@@ -234,6 +234,12 @@ func ParseOutlet(in config.LoggingOutletEnum) (o logger.Outlet, level logger.Lev
 			break
 		}
 		o, err = parseSyslogOutlet(v, f)
+	case *config.FileLoggingOutlet:
+		level, f, err = parseCommon(v.LoggingOutletCommon)
+		if err != nil {
+			break
+		}
+		o, err = parseFileOutlet(v, f)
 	default:
 		panic(v)
 	}
@@ -301,3 +307,33 @@ func parseSyslogOutlet(in *config.SyslogLoggingOutlet, formatter EntryFormatter)
 	out.RetryInterval = in.RetryInterval
 	return out, nil
 }
+
+func parseFileOutlet(
+	in *config.FileLoggingOutlet, formatter EntryFormatter,
+) (*FileOutlet, error) {
+	flags := MetadataNone
+	if in.Time {
+		flags |= MetadataTime
+	}
+	if in.LogLevel {
+		flags |= MetadataLevel
+	}
+
+	formatter.SetMetadataFlags(flags)
+	outlet := FileOutlet{
+		filename:  in.FileName,
+		formatter: formatter,
+	}
+
+	if in.Template != "" {
+		if err := outlet.ParseTemplate(in.Template); err != nil {
+			return nil, err
+		}
+	}
+
+	if err := outlet.Open(); err != nil {
+		return nil, err
+	}
+
+	return &outlet, nil
+}
diff --git daemon/logging/logging_outlets.go daemon/logging/logging_outlets.go
index b1638e8..a3cc242 100644
--- daemon/logging/logging_outlets.go
+++ daemon/logging/logging_outlets.go
@@ -4,9 +4,13 @@ import (
 	"bytes"
 	"context"
 	"crypto/tls"
+	"fmt"
 	"io"
 	"log/syslog"
 	"net"
+	"os"
+	"syscall"
+	"text/template"
 	"time"
 
 	"github.com/pkg/errors"
@@ -170,5 +174,121 @@ func (o *SyslogOutlet) WriteEntry(entry logger.Entry) error {
 	default:
 		return o.writer.Err(s) // write as error as reaching this case is in fact an error
 	}
+}
+
+type FileOutlet struct {
+	file      *os.File
+	filename  string
+	formatter EntryFormatter
+	template  *template.Template
+	writer    io.Writer
+}
+
+func (self *FileOutlet) WriteEntry(entry logger.Entry) error {
+	bytes, err := self.formatter.Format(&entry)
+	if err != nil {
+		return err
+	}
+
+	if err := self.reOpenIfNotExists(); err != nil {
+		return nil
+	}
+
+	if self.template == nil {
+		return self.writeBytes(bytes)
+	}
+
+	if err := self.writeTemplate(entry.Time, string(bytes)); err != nil {
+		return err
+	}
+
+	return nil
+}
+
+func (self *FileOutlet) reOpenIfNotExists() error {
+	finfo, err := self.file.Stat()
+	if err != nil {
+		return fmt.Errorf("failed stat of %q: %w", self.filename, err)
+	}
+
+	nlink := uint64(0)
+	if finfo.Sys() != nil {
+		if stat, ok := finfo.Sys().(*syscall.Stat_t); ok {
+			nlink = stat.Nlink
+		}
+	}
+	if nlink > 0 {
+		return nil
+	}
+
+	return self.reOpen()
+}
+
+func (self *FileOutlet) reOpen() error {
+	if err := self.file.Close(); err != nil {
+		return fmt.Errorf("failed close %q: %w", self.filename, err)
+	}
+
+	return self.Open()
+}
+
+func (self *FileOutlet) Open() error {
+	f, err := os.OpenFile(self.filename, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
+	if err != nil {
+		return fmt.Errorf("file outlet: %w", err)
+	}
+	self.file = f
+	self.writer = f
+
+	return nil
+}
+
+func (self *FileOutlet) ParseTemplate(templateText string) error {
+	funcMap := template.FuncMap{
+		"formatTime": func(t time.Time, layout string) string {
+			return t.Format(layout)
+		},
+	}
+
+	tmpl, err := template.New("").Funcs(funcMap).Parse(templateText)
+	if err != nil {
+		return fmt.Errorf("failed parse template %q: %w", templateText, err)
+	}
+	self.template = tmpl
+
+	return nil
+}
+
+func (self *FileOutlet) writeTemplate(t time.Time, msg string) error {
+	data := struct {
+		Time    time.Time
+		Pid     int
+		Message string
+	}{
+		Time:    t,
+		Pid:     os.Getpid(),
+		Message: msg,
+	}
+
+	if err := self.template.Execute(self.writer, data); err != nil {
+		return fmt.Errorf("failed execute template: %w", err)
+	}
+
+	if _, err := self.writer.Write([]byte("\n")); err != nil {
+		return fmt.Errorf("failed write to %q: %w", self.filename, err)
+	}
+
+	return nil
+}
+
+func (self *FileOutlet) writeBytes(bytes []byte) error {
+	if _, err := self.writer.Write(bytes); err != nil {
+		return fmt.Errorf("failed write to %q: %w", self.filename, err)
+	}
+
+	if _, err := self.writer.Write([]byte("\n")); err != nil {
+		return fmt.Errorf("failed write to %q: %w", self.filename, err)
+	}
 
+	return nil
 }
diff --git docs/configuration/filter_syntax.rst docs/configuration/filter_syntax.rst
index b18172f..2765a1b 100644
--- docs/configuration/filter_syntax.rst
+++ docs/configuration/filter_syntax.rst
@@ -15,8 +15,10 @@ The following rules determine which result is chosen for a given filesystem path
 * Non-wildcard patterns (full path patterns) win over *subtree wildcards* (`<` at end of pattern)
 * If the path in question does not match any pattern, the result is ``false``.
 
-The **subtree wildcard** ``<`` means "the dataset left of ``<`` and all its children".
-   
+The **subtree wildcard** ``<`` means "the dataset left of ``<`` and all its
+children". On the right of ``<`` can be added shell pattern, which filters
+children of the dataset.
+
 .. TIP::
   You can try out patterns for a configured job using the ``zrepl test filesystems`` subcommand for push and source jobs.
 
@@ -50,7 +52,8 @@ The following configuration demonstrates all rules presented above.
       filesystems: {
         "tank<": true,          # rule 1
         "tank/foo<": false,     # rule 2
-        "tank/foo/bar": true,  # rule 3
+        "tank/foo/bar": true,   # rule 3
+        "tank/bar</*/foo": true # rule 4
       }
       ...
 
@@ -64,4 +67,7 @@ Which rule applies to given path, and what is the result?
     tank/foo/bar     => 3    true
     zroot            => NONE false
     tank/var/log     => 1    true
-
+    tank/bar/a       => 4    false
+    tank/bar/a/foo   => 4    true
+    tank/bar/b       => 4    false
+    tank/bar/b/foo   => 4    true
diff --git docs/configuration/jobs.rst docs/configuration/jobs.rst
index 523e534..5b932ca 100644
--- docs/configuration/jobs.rst
+++ docs/configuration/jobs.rst
@@ -24,8 +24,13 @@ Job Type ``push``
       - |connect-transport|
     * - ``filesystems``
       - |filter-spec| for filesystems to be snapshotted and pushed to the sink
+    * - ``interval``
+      - | Interval at which to push to the sink (e.g. ``10m``) if
+        | ``snapshotting`` configured as ``manual``. This field is optional and
+        | if not defined, than ``snapshotting`` does the job. Also this field
+        | ignored if ``snapshotting`` isn't ``manual``.
     * - ``send``
-      - |send-options| 
+      - |send-options|
     * - ``snapshotting``
       - |snapshotting-spec|
     * - ``pruning``
diff --git docs/configuration/logging.rst docs/configuration/logging.rst
index aeed2ba..e57e787 100644
--- docs/configuration/logging.rst
+++ docs/configuration/logging.rst
@@ -106,6 +106,54 @@ Outlets
 
 Outlets are the destination for log entries.
 
+.. _logging-outlet-file:
+
+``file`` Outlet
+-----------------
+
+.. list-table::
+    :widths: 10 90
+    :header-rows: 1
+
+    * - Parameter
+      - Comment
+    * - ``type``
+      - ``file``
+    * - ``level``
+      -  minimum  :ref:`log level <logging-levels>`
+    * - ``format``
+      - output :ref:`format <logging-formats>`
+    * - ``time``
+      - always include time in output (``true`` or ``false``). Default is ``true``.
+    * - ``log_level``
+      - include log level into output (``true`` or ``false``). Default is ``true``.
+    * - ``filename``
+      - path of the log file
+    * - ``template``
+      - format output by Go template string
+
+Writes all log entries with minimum level ``level`` formatted by ``format`` to
+file from ``filename``. This outlet automatically detects the log file was
+rotated and reopens it.
+
+If ``template`` configured, log entries formatted by this template. For instance
+this configuration
+
+::
+
+    - type: "file"
+      level:  "info"
+      format: "human"
+      filename: "/var/log/zrepl.log"
+      time: false
+      template: '{{formatTime .Time "Jan _2 15:04:05"}} zrepl[{{.Pid}}]: {{.Message}}'
+
+formats log entries like ::
+
+  ``Oct 22 21:51:02 zrepl[29094]: [INFO][job-name][job][abcd$dcab$abcd.dcab]: wait for wakeups``.
+
+Can be specified many times with different ``filename``.
+
 .. _logging-outlet-stdout:
 
 ``stdout`` Outlet
diff --git endpoint/endpoint.go endpoint/endpoint.go
index 1ae9dc9..92d9227 100644
--- endpoint/endpoint.go
+++ endpoint/endpoint.go
@@ -38,6 +38,7 @@ type SenderConfig struct {
 	SendSaved            bool
 
 	BandwidthLimit bandwidthlimit.Config
+	ExecPipe       [][]string
 }
 
 func (c *SenderConfig) Validate() error {
@@ -305,7 +306,7 @@ func (s *Sender) Send(ctx context.Context, r *pdu.SendReq) (*pdu.SendRes, io.Rea
 	}()
 
 	var sendStream io.ReadCloser
-	sendStream, err = zfs.ZFSSend(ctx, sendArgs)
+	sendStream, err = zfs.ZFSSend(ctx, sendArgs, s.config.ExecPipe...)
 	if err != nil {
 		// it's ok to not destroy the abstractions we just created here, a new send attempt will take care of it
 		return nil, nil, errors.Wrap(err, "zfs send failed")
@@ -479,6 +480,8 @@ type ReceiverConfig struct {
 	BandwidthLimit bandwidthlimit.Config
 
 	PlaceholderEncryption PlaceholderCreationEncryptionProperty
+
+	ExecPipe [][]string
 }
 
 //go:generate enumer -type=PlaceholderCreationEncryptionProperty -transform=kebab -trimprefix=PlaceholderCreationEncryptionProperty
@@ -923,7 +926,10 @@ func (s *Receiver) Receive(ctx context.Context, req *pdu.ReceiveReq, receive io.
 	log.WithField("opts", fmt.Sprintf("%#v", recvOpts)).Debug("start receive command")
 
 	snapFullPath := to.FullPath(lp.ToString())
-	if err := zfs.ZFSRecv(ctx, lp.ToString(), to, chainedio.NewChainedReader(&peek, receive), recvOpts); err != nil {
+	if err := zfs.ZFSRecv(
+		ctx, lp.ToString(), to, chainedio.NewChainedReader(&peek, receive),
+		recvOpts, s.conf.ExecPipe...,
+	); err != nil {
 
 		// best-effort rollback of placeholder state if the recv didn't start
 		_, resumableStatePresent := err.(*zfs.RecvFailedWithResumeTokenErr)
diff --git pruning/keep_last_n.go pruning/keep_last_n.go
index 023568d..73f00cc 100644
--- pruning/keep_last_n.go
+++ pruning/keep_last_n.go
@@ -33,11 +33,6 @@ func NewKeepLastN(n int, regex string) (*KeepLastN, error) {
 }
 
 func (k KeepLastN) KeepRule(snaps []Snapshot) (destroyList []Snapshot) {
-
-	if k.n > len(snaps) {
-		return []Snapshot{}
-	}
-
 	matching, notMatching := partitionSnapList(snaps, func(snapshot Snapshot) bool {
 		return k.re.MatchString(snapshot.Name())
 	})
diff --git pruning/keep_last_n_test.go pruning/keep_last_n_test.go
index 4283e3e..17e7394 100644
--- pruning/keep_last_n_test.go
+++ pruning/keep_last_n_test.go
@@ -90,7 +90,7 @@ func TestKeepLastN(t *testing.T) {
 				stubSnap{"a2", false, o(12)},
 			},
 			rules: []KeepRule{
-				MustKeepLastN(3, "a"),
+				MustKeepLastN(4, "a"),
 			},
 			expDestroy: map[string]bool{
 				"b1": true,
diff --git zfs/zfs.go zfs/zfs.go
index a8bf86d..bb7365e 100644
--- zfs/zfs.go
+++ zfs/zfs.go
@@ -930,8 +930,9 @@ var ErrEncryptedSendNotSupported = fmt.Errorf("raw sends which are required for
 // (if from is "" a full ZFS send is done)
 //
 // Returns ErrEncryptedSendNotSupported if encrypted send is requested but not supported by CLI
-func ZFSSend(ctx context.Context, sendArgs ZFSSendArgsValidated) (*SendStream, error) {
-
+func ZFSSend(
+	ctx context.Context, sendArgs ZFSSendArgsValidated, pipeCmds ...[]string,
+) (*SendStream, error) {
 	args := make([]string, 0)
 	args = append(args, "send")
 
@@ -972,10 +973,19 @@ func ZFSSend(ctx context.Context, sendArgs ZFSSendArgsValidated) (*SendStream, e
 		Stderr: stderrBuf,
 	})
 
+	pipeReader, err := cmd.Pipe(stdoutReader, stderrBuf, pipeCmds...)
+	if err != nil {
+		cancel()
+		stdoutWriter.Close()
+		stdoutReader.Close()
+		return nil, err
+	}
+
 	if err := cmd.Start(); err != nil {
 		cancel()
 		stdoutWriter.Close()
 		stdoutReader.Close()
+		_ = cmd.WaitPipe()
 		return nil, errors.Wrap(err, "cannot start zfs send command")
 	}
 	// close our writing-end of the pipe so that we don't wait for ourselves when reading from the reading  end
@@ -983,7 +993,7 @@ func ZFSSend(ctx context.Context, sendArgs ZFSSendArgsValidated) (*SendStream, e
 
 	stream := &SendStream{
 		cmd:          cmd,
-		stdoutReader: stdoutReader,
+		stdoutReader: pipeReader,
 		stderrBuf:    stderrBuf,
 	}
 	_ = cancel // the SendStream.killAndWait() will kill the process
@@ -1207,8 +1217,10 @@ func (opts RecvOptions) buildRecvFlags() []string {
 
 const RecvStderrBufSiz = 1 << 15
 
-func ZFSRecv(ctx context.Context, fs string, v *ZFSSendArgVersion, stream io.ReadCloser, opts RecvOptions) (err error) {
-
+func ZFSRecv(
+	ctx context.Context, fs string, v *ZFSSendArgVersion, stream io.ReadCloser,
+	opts RecvOptions, pipeCmds ...[]string,
+) (err error) {
 	if err := v.ValidateInMemory(fs); err != nil {
 		return errors.Wrap(err, "invalid version")
 	}
@@ -1280,8 +1292,15 @@ func ZFSRecv(ctx context.Context, fs string, v *ZFSSendArgVersion, stream io.Rea
 		return err
 	}
 
+	pipeReader, err := cmd.WithLeftPipe().Pipe(stdin, stderr, pipeCmds...)
+	if err != nil {
+		stdinWriter.Close()
+		stdin.Close()
+		return err
+	}
+
 	cmd.SetStdio(zfscmd.Stdio{
-		Stdin:  stdin,
+		Stdin:  pipeReader,
 		Stdout: stdout,
 		Stderr: stderr,
 	})
@@ -1289,6 +1308,7 @@ func ZFSRecv(ctx context.Context, fs string, v *ZFSSendArgVersion, stream io.Rea
 	if err = cmd.Start(); err != nil {
 		stdinWriter.Close()
 		stdin.Close()
+		_ = cmd.WaitPipe()
 		return err
 	}
 	stdin.Close()
@@ -1301,40 +1321,30 @@ func ZFSRecv(ctx context.Context, fs string, v *ZFSSendArgVersion, stream io.Rea
 
 	debug("started")
 
-	copierErrChan := make(chan error)
-	go func() {
-		_, err := io.Copy(stdinWriter, stream)
-		copierErrChan <- err
-		stdinWriter.Close()
-	}()
-	waitErrChan := make(chan error)
-	go func() {
-		defer close(waitErrChan)
-		if err = cmd.Wait(); err != nil {
-			if rtErr := tryRecvErrorWithResumeToken(ctx, stderr.String()); rtErr != nil {
-				waitErrChan <- rtErr
-			} else if owErr := tryRecvDestroyOrOverwriteEncryptedErr(stderr.Bytes()); owErr != nil {
-				waitErrChan <- owErr
-			} else if readErr := tryRecvCannotReadFromStreamErr(stderr.Bytes()); readErr != nil {
-				waitErrChan <- readErr
-			} else {
-				waitErrChan <- &ZFSError{
-					Stderr:  stderr.Bytes(),
-					WaitErr: err,
-				}
-			}
-			return
-		}
-	}()
-
-	copierErr := <-copierErrChan
+	_, copierErr := io.Copy(stdinWriter, stream)
 	debug("copierErr: %T %s", copierErr, copierErr)
+	stdinWriter.Close()
+
 	if copierErr != nil {
 		debug("killing zfs recv command after copierErr")
 		cancelCmd()
 	}
 
-	waitErr := <-waitErrChan
+	var waitErr error
+	if err = cmd.Wait(); err != nil {
+		if rtErr := tryRecvErrorWithResumeToken(ctx, stderr.String()); rtErr != nil {
+			waitErr = rtErr
+		} else if owErr := tryRecvDestroyOrOverwriteEncryptedErr(stderr.Bytes()); owErr != nil {
+			waitErr = owErr
+		} else if readErr := tryRecvCannotReadFromStreamErr(stderr.Bytes()); readErr != nil {
+			waitErr = readErr
+		} else {
+			waitErr = &ZFSError{
+				Stderr:  stderr.Bytes(),
+				WaitErr: err,
+			}
+		}
+	}
 	debug("waitErr: %T %s", waitErr, waitErr)
 
 	if copierErr == nil && waitErr == nil {
diff --git zfs/zfscmd/zfscmd.go zfs/zfscmd/zfscmd.go
index 094f310..d11bd9f 100644
--- zfs/zfscmd/zfscmd.go
+++ zfs/zfscmd/zfscmd.go
@@ -7,6 +7,7 @@ package zfscmd
 
 import (
 	"context"
+	"fmt"
 	"io"
 	"os"
 	"os/exec"
@@ -24,6 +25,9 @@ type Cmd struct {
 	mtx                                      sync.RWMutex
 	startedAt, waitStartedAt, waitReturnedAt time.Time
 	waitReturnEndSpanCb                      trace.DoneFunc
+
+	pipeCmds []*exec.Cmd
+	pipeLeft bool
 }
 
 func CommandContext(ctx context.Context, name string, arg ...string) *Cmd {
@@ -72,7 +76,26 @@ func (c *Cmd) SetStdio(stdio Stdio) {
 }
 
 func (c *Cmd) String() string {
-	return strings.Join(c.cmd.Args, " ") // includes argv[0] if initialized with CommandContext, that's the only way we o it
+	if len(c.pipeCmds) == 0 {
+		return strings.Join(c.cmd.Args, " ") // includes argv[0] if initialized with CommandContext, that's the only way we o it
+	}
+
+	var s strings.Builder
+	if c.pipeLeft {
+		for _, cmd := range c.pipeCmds {
+			s.WriteString(strings.Join(cmd.Args, " "))
+			s.WriteString(" | ")
+		}
+		s.WriteString(strings.Join(c.cmd.Args, " "))
+	} else {
+		s.WriteString(strings.Join(c.cmd.Args, " "))
+		for _, cmd := range c.pipeCmds {
+			s.WriteString(" | ")
+			s.WriteString(strings.Join(cmd.Args, " "))
+		}
+	}
+
+	return s.String()
 }
 
 func (c *Cmd) log() Logger {
@@ -88,7 +111,7 @@ func (c *Cmd) log() Logger {
 // If this method returns an error, the Cmd instance is invalid. Start must not be called repeatedly.
 func (c *Cmd) Start() (err error) {
 	c.startPre(true)
-	err = c.cmd.Start()
+	err = c.startPipe()
 	c.startPost(err)
 	return err
 }
@@ -109,7 +132,7 @@ func (c *Cmd) Process() *os.Process {
 // Only call this method after a successful call to .Start().
 func (c *Cmd) Wait() (err error) {
 	c.waitPre()
-	err = c.cmd.Wait()
+	err = c.WaitPipe()
 	c.waitPost(err)
 	return err
 }
@@ -213,3 +236,68 @@ func (c *Cmd) Runtime() time.Duration {
 func (c *Cmd) TestOnly_ExecCmd() *exec.Cmd {
 	return c.cmd
 }
+
+func (c *Cmd) Pipe(
+	stdin io.ReadCloser, stderr io.Writer, cmds ...[]string,
+) (io.ReadCloser, error) {
+	for _, pipeCmd := range c.buildPipeCmds(cmds) {
+		r, err := pipeCmd.StdoutPipe()
+		if err != nil {
+			return nil, fmt.Errorf(
+				"failed create stdout pipe for %q: %w", pipeCmd.String(), err)
+		}
+		pipeCmd.Stdin = stdin
+		pipeCmd.Stderr = stderr
+		c.pipeCmds = append(c.pipeCmds, pipeCmd)
+		stdin = r
+	}
+	return stdin, nil
+}
+
+func (c *Cmd) buildPipeCmds(cmds [][]string) []*exec.Cmd {
+	pipeCmds := make([]*exec.Cmd, len(cmds))
+	for i := range cmds {
+		name := cmds[i][0]
+		var args []string
+		if len(cmds[i]) > 1 {
+			args = cmds[i][1:]
+		}
+		pipeCmds[i] = exec.CommandContext(c.ctx, name, args...)
+	}
+	return pipeCmds
+}
+
+func (c *Cmd) startPipe() error {
+	if err := c.cmd.Start(); err != nil {
+		return err
+	}
+	for _, cmd := range c.pipeCmds {
+		if err := cmd.Start(); err != nil {
+			return fmt.Errorf("failed start %q: %w", cmd.String(), err)
+		}
+	}
+	return nil
+}
+
+func (c *Cmd) WaitPipe() error {
+	var firstErr error
+	if c.cmd.Process != nil {
+		if err := c.cmd.Wait(); err != nil {
+			firstErr = err
+		}
+	}
+	for _, cmd := range c.pipeCmds {
+		if cmd.Process == nil {
+			break
+		}
+		if err := cmd.Wait(); err != nil && firstErr == nil {
+			firstErr = fmt.Errorf("failed wait %q: %w", cmd.String(), err)
+		}
+	}
+	return firstErr
+}
+
+func (c *Cmd) WithLeftPipe() *Cmd {
+	c.pipeLeft = true
+	return c
+}
diff --git zfs/zfscmd/zfscmd_platform_test.go zfs/zfscmd/zfscmd_platform_test.go
index 1a33ba5..26a99ba 100644
--- zfs/zfscmd/zfscmd_platform_test.go
+++ zfs/zfscmd/zfscmd_platform_test.go
@@ -121,5 +121,87 @@ func TestSigpipe(t *testing.T) {
 
 	err = cmd.Wait()
 	require.EqualError(t, err, "exit status 23")
+}
 
+func TestCmd_Pipe(t *testing.T) {
+	ctx := context.Background()
+
+	tests := []struct {
+		name         string
+		cmd          *Cmd
+		pipeCmds     [][]string
+		pipeLeft     bool
+		wantCmdStr   string
+		waitErr      bool
+		assertStdout func(t *testing.T, b []byte)
+	}{
+		{
+			name:       "no error",
+			cmd:        CommandContext(ctx, "echo", "foobar"),
+			pipeCmds:   [][]string{{"tr", "a-z", "A-Z"}},
+			wantCmdStr: "echo foobar | tr a-z A-Z",
+			assertStdout: func(t *testing.T, b []byte) {
+				assert.Equal(t, "FOOBAR", strings.TrimSpace(string(b)))
+			},
+		},
+		{
+			name:       "pipe on the left side",
+			cmd:        CommandContext(ctx, "echo", "foobar"),
+			pipeCmds:   [][]string{{"true"}},
+			pipeLeft:   true,
+			wantCmdStr: "true | echo foobar",
+		},
+		{
+			name:       "cmd error",
+			cmd:        CommandContext(ctx, "false"),
+			pipeCmds:   [][]string{{"tr", "a-z", "A-Z"}},
+			wantCmdStr: "false | tr a-z A-Z",
+			waitErr:    true,
+		},
+		{
+			name:       "pipe error",
+			cmd:        CommandContext(ctx, "echo", "foobar"),
+			pipeCmds:   [][]string{{"false"}},
+			wantCmdStr: "echo foobar | false",
+			waitErr:    true,
+		},
+	}
+
+	for _, tt := range tests {
+		t.Run(tt.name, func(t *testing.T) {
+			r, w, err := os.Pipe()
+			require.NoError(t, err)
+
+			var stderr strings.Builder
+			tt.cmd.SetStdio(Stdio{
+				Stdout: w,
+				Stderr: &stderr,
+			})
+
+			if tt.pipeLeft {
+				assert.Same(t, tt.cmd, tt.cmd.WithLeftPipe())
+			}
+
+			stdout, err := tt.cmd.Pipe(r, &stderr, tt.pipeCmds...)
+			require.NoError(t, err)
+			assert.Equal(t, tt.wantCmdStr, tt.cmd.String())
+			require.NoError(t, tt.cmd.startPipe())
+			require.NoError(t, w.Close())
+
+			b, err := io.ReadAll(stdout)
+			require.NoError(t, err)
+			require.NoError(t, r.Close())
+
+			if tt.waitErr {
+				require.Error(t, tt.cmd.WaitPipe())
+			} else {
+				require.NoError(t, tt.cmd.WaitPipe())
+			}
+			assert.Empty(t, stderr.String())
+
+			if tt.assertStdout != nil {
+				tt.assertStdout(t, b)
+			}
+		})
+	}
 }
