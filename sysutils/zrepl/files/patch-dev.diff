diff --git config/config.go config/config.go
index 6c56cc3..bd2cc37 100644
--- config/config.go
+++ config/config.go
@@ -146,9 +146,10 @@ type PlaceholderRecvOptions struct {
 
 type PushJob struct {
 	ActiveJob    `yaml:",inline"`
-	Snapshotting SnapshottingEnum  `yaml:"snapshotting"`
-	Filesystems  FilesystemsFilter `yaml:"filesystems"`
-	Send         *SendOptions      `yaml:"send,fromdefaults,optional"`
+	Interval     *PositiveDurationOrManual `yaml:"interval,optional"`
+	Snapshotting SnapshottingEnum          `yaml:"snapshotting"`
+	Filesystems  FilesystemsFilter         `yaml:"filesystems"`
+	Send         *SendOptions              `yaml:"send,fromdefaults,optional"`
 }
 
 func (j *PushJob) GetFilesystems() FilesystemsFilter { return j.Filesystems }
@@ -421,6 +422,14 @@ type LoggingOutletCommon struct {
 	Format string `yaml:"format"`
 }
 
+type FileLoggingOutlet struct {
+	LoggingOutletCommon `yaml:",inline"`
+	FileName            string `yaml:"filename"`
+	Time                bool   `yaml:"time,default=true"`
+	LogLevel            bool   `yaml:"log_level,default=true"`
+	Template            string `yaml:"template"`
+}
+
 type StdoutLoggingOutlet struct {
 	LoggingOutletCommon `yaml:",inline"`
 	Time                bool `yaml:"time,default=true"`
@@ -582,6 +591,7 @@ func (t *SnapshottingEnum) UnmarshalYAML(u func(interface{}, bool) error) (err e
 
 func (t *LoggingOutletEnum) UnmarshalYAML(u func(interface{}, bool) error) (err error) {
 	t.Ret, err = enumUnmarshal(u, map[string]interface{}{
+		"file":   &FileLoggingOutlet{},
 		"stdout": &StdoutLoggingOutlet{},
 		"syslog": &SyslogLoggingOutlet{},
 		"tcp":    &TCPLoggingOutlet{},
@@ -665,7 +675,6 @@ var ConfigFileDefaultLocations = []string{
 }
 
 func ParseConfig(path string) (i *Config, err error) {
-
 	if path == "" {
 		// Try default locations
 		for _, l := range ConfigFileDefaultLocations {
diff --git daemon/filters/fsmapfilter.go daemon/filters/fsmapfilter.go
index b28da20..eb9a92e 100644
--- daemon/filters/fsmapfilter.go
+++ daemon/filters/fsmapfilter.go
@@ -2,6 +2,7 @@ package filters
 
 import (
 	"fmt"
+	"path/filepath"
 	"strings"
 
 	"github.com/pkg/errors"
@@ -24,6 +25,19 @@ type datasetMapFilterEntry struct {
 	// we have to convert it to the desired rep dynamically
 	mapping      string
 	subtreeMatch bool
+
+	// subtreePattern contains a shell pattern for checking is a subtree matching
+	// this definition or not. See pattern syntax in [filepath.Match].
+	subtreePattern string
+}
+
+func (e datasetMapFilterEntry) HasPattern() bool {
+	return e.subtreePattern != ""
+}
+
+func (e datasetMapFilterEntry) Match(path *zfs.DatasetPath) (bool, error) {
+	fullPattern := filepath.Join(e.path.ToString(), e.subtreePattern)
+	return filepath.Match(fullPattern, path.ToString())
 }
 
 func NewDatasetMapFilter(capacity int, filterMode bool) *DatasetMapFilter {
@@ -43,28 +57,33 @@ func (m *DatasetMapFilter) Add(pathPattern, mapping string) (err error) {
 
 	// assert path glob adheres to spec
 	const SUBTREE_PATTERN string = "<"
-	patternCount := strings.Count(pathPattern, SUBTREE_PATTERN)
-	switch {
-	case patternCount > 1:
-	case patternCount == 1 && !strings.HasSuffix(pathPattern, SUBTREE_PATTERN):
-		err = fmt.Errorf("pattern invalid: only one '<' at end of string allowed")
-		return
+	pathStr, pattern, found := strings.Cut(pathPattern, SUBTREE_PATTERN)
+
+	if pattern != "" {
+		if strings.Contains(pattern, SUBTREE_PATTERN) {
+			return fmt.Errorf(
+				"invalid shell pattern %q in path pattern %q: '<' not allowed in shell patterns",
+				pattern, pathPattern)
+		}
+		if _, err := filepath.Match(pattern, ""); err != nil {
+			return fmt.Errorf(
+				"invalid shell pattern %q in %q: %w", pattern, pathPattern, err)
+		}
 	}
 
-	pathStr := strings.TrimSuffix(pathPattern, SUBTREE_PATTERN)
 	path, err := zfs.NewDatasetPath(pathStr)
 	if err != nil {
 		return fmt.Errorf("pattern is not a dataset path: %s", err)
 	}
 
 	entry := datasetMapFilterEntry{
-		path:         path,
-		mapping:      mapping,
-		subtreeMatch: patternCount > 0,
+		path:           path,
+		mapping:        mapping,
+		subtreeMatch:   found,
+		subtreePattern: pattern,
 	}
 	m.entries = append(m.entries, entry)
 	return
-
 }
 
 // find the most specific prefix mapping we have
@@ -155,9 +174,17 @@ func (m DatasetMapFilter) Filter(p *zfs.DatasetPath) (pass bool, err error) {
 		pass = false
 		return
 	}
+
 	me := m.entries[mi]
-	pass, err = m.parseDatasetFilterResult(me.mapping)
-	return
+	if me.HasPattern() {
+		if matched, err := me.Match(p); err != nil {
+			return false, err
+		} else if !matched {
+			return false, nil
+		}
+	}
+
+	return m.parseDatasetFilterResult(me.mapping)
 }
 
 func (m DatasetMapFilter) UserSpecifiedDatasets() (datasets zfs.UserSpecifiedDatasetsSet) {
diff --git daemon/filters/fsmapfilter_test.go daemon/filters/fsmapfilter_test.go
index eccd59d..9bc58b5 100644
--- daemon/filters/fsmapfilter_test.go
+++ daemon/filters/fsmapfilter_test.go
@@ -54,6 +54,22 @@ func TestDatasetMapFilter(t *testing.T) {
 				"tank/home/bob/downloads": false,
 			},
 		},
+		{
+			name: "with shell patterns",
+			filter: map[string]string{
+				"tank/home</*/foo": "ok",
+				"tank/home/mark<":  "!",
+			},
+			checkPass: map[string]bool{
+				"tank/home":              false,
+				"tank/home/bob":          false,
+				"tank/home/bob/foo":      true,
+				"tank/home/alice/foo":    true,
+				"tank/home/john/foo/bar": false,
+				"tank/home/john/bar":     false,
+				"tank/home/mark/foo":     false,
+			},
+		},
 	}
 
 	for tc := range tcs {
diff --git daemon/job/active.go daemon/job/active.go
index b857aea..1e3e62d 100644
--- daemon/job/active.go
+++ daemon/job/active.go
@@ -102,6 +102,7 @@ type modePush struct {
 	senderConfig  *endpoint.SenderConfig
 	plannerPolicy *logic.PlannerPolicy
 	snapper       snapper.Snapper
+	interval      *config.PositiveDurationOrManual
 }
 
 func (m *modePush) ConnectEndpoints(ctx context.Context, connecter transport.Connecter) {
@@ -132,8 +133,32 @@ func (m *modePush) Type() Type { return TypePush }
 
 func (m *modePush) PlannerPolicy() logic.PlannerPolicy { return *m.plannerPolicy }
 
-func (m *modePush) RunPeriodic(ctx context.Context, wakeUpCommon chan<- struct{}) {
-	m.snapper.Run(ctx, wakeUpCommon)
+func (m *modePush) RunPeriodic(
+	ctx context.Context, wakeUpCommon chan<- struct{},
+) {
+	if m.interval == nil {
+		m.snapper.Run(ctx, wakeUpCommon)
+		return
+	}
+
+	t := time.NewTicker(m.interval.Interval)
+	defer t.Stop()
+
+	for {
+		select {
+		case <-t.C:
+			select {
+			case wakeUpCommon <- struct{}{}:
+			default:
+				GetLogger(ctx).
+					WithField("push_interval", m.interval).
+					Warn("push job took longer than push interval")
+				wakeUpCommon <- struct{}{} // block anyways, to queue up the wakeup
+			}
+		case <-ctx.Done():
+			return
+		}
+	}
 }
 
 func (m *modePush) SnapperReport() *snapper.Report {
@@ -153,6 +178,10 @@ func modePushFromConfig(g *config.Global, in *config.PushJob, jobID endpoint.Job
 	m := &modePush{}
 	var err error
 
+	if _, ok := in.Snapshotting.Ret.(*config.SnapshottingManual); ok {
+		m.interval = in.Interval
+	}
+
 	m.senderConfig, err = buildSenderConfig(in, jobID)
 	if err != nil {
 		return nil, errors.Wrap(err, "sender config")
diff --git daemon/job/build_jobs.go daemon/job/build_jobs.go
index be630e9..dc2de92 100644
--- daemon/job/build_jobs.go
+++ daemon/job/build_jobs.go
@@ -24,21 +24,6 @@ func JobsFromConfig(c *config.Config, parseFlags config.ParseFlags) ([]Job, erro
 		js[i] = j
 	}
 
-	// receiving-side root filesystems must not overlap
-	{
-		rfss := make([]string, 0, len(js))
-		for _, j := range js {
-			jrfs, ok := j.OwnedDatasetSubtreeRoot()
-			if !ok {
-				continue
-			}
-			rfss = append(rfss, jrfs.ToString())
-		}
-		if err := validateReceivingSidesDoNotOverlap(rfss); err != nil {
-			return nil, err
-		}
-	}
-
 	return js, nil
 }
 
diff --git daemon/logging/build_logging.go daemon/logging/build_logging.go
index 0aff33e..d56e3d9 100644
--- daemon/logging/build_logging.go
+++ daemon/logging/build_logging.go
@@ -234,6 +234,12 @@ func ParseOutlet(in config.LoggingOutletEnum) (o logger.Outlet, level logger.Lev
 			break
 		}
 		o, err = parseSyslogOutlet(v, f)
+	case *config.FileLoggingOutlet:
+		level, f, err = parseCommon(v.LoggingOutletCommon)
+		if err != nil {
+			break
+		}
+		o, err = parseFileOutlet(v, f)
 	default:
 		panic(v)
 	}
@@ -301,3 +307,33 @@ func parseSyslogOutlet(in *config.SyslogLoggingOutlet, formatter EntryFormatter)
 	out.RetryInterval = in.RetryInterval
 	return out, nil
 }
+
+func parseFileOutlet(
+	in *config.FileLoggingOutlet, formatter EntryFormatter,
+) (*FileOutlet, error) {
+	flags := MetadataNone
+	if in.Time {
+		flags |= MetadataTime
+	}
+	if in.LogLevel {
+		flags |= MetadataLevel
+	}
+
+	formatter.SetMetadataFlags(flags)
+	outlet := FileOutlet{
+		filename:  in.FileName,
+		formatter: formatter,
+	}
+
+	if in.Template != "" {
+		if err := outlet.ParseTemplate(in.Template); err != nil {
+			return nil, err
+		}
+	}
+
+	if err := outlet.Open(); err != nil {
+		return nil, err
+	}
+
+	return &outlet, nil
+}
diff --git daemon/logging/logging_outlets.go daemon/logging/logging_outlets.go
index b1638e8..a3cc242 100644
--- daemon/logging/logging_outlets.go
+++ daemon/logging/logging_outlets.go
@@ -4,9 +4,13 @@ import (
 	"bytes"
 	"context"
 	"crypto/tls"
+	"fmt"
 	"io"
 	"log/syslog"
 	"net"
+	"os"
+	"syscall"
+	"text/template"
 	"time"
 
 	"github.com/pkg/errors"
@@ -170,5 +174,121 @@ func (o *SyslogOutlet) WriteEntry(entry logger.Entry) error {
 	default:
 		return o.writer.Err(s) // write as error as reaching this case is in fact an error
 	}
+}
+
+type FileOutlet struct {
+	file      *os.File
+	filename  string
+	formatter EntryFormatter
+	template  *template.Template
+	writer    io.Writer
+}
+
+func (self *FileOutlet) WriteEntry(entry logger.Entry) error {
+	bytes, err := self.formatter.Format(&entry)
+	if err != nil {
+		return err
+	}
+
+	if err := self.reOpenIfNotExists(); err != nil {
+		return nil
+	}
+
+	if self.template == nil {
+		return self.writeBytes(bytes)
+	}
+
+	if err := self.writeTemplate(entry.Time, string(bytes)); err != nil {
+		return err
+	}
+
+	return nil
+}
+
+func (self *FileOutlet) reOpenIfNotExists() error {
+	finfo, err := self.file.Stat()
+	if err != nil {
+		return fmt.Errorf("failed stat of %q: %w", self.filename, err)
+	}
+
+	nlink := uint64(0)
+	if finfo.Sys() != nil {
+		if stat, ok := finfo.Sys().(*syscall.Stat_t); ok {
+			nlink = stat.Nlink
+		}
+	}
+	if nlink > 0 {
+		return nil
+	}
+
+	return self.reOpen()
+}
+
+func (self *FileOutlet) reOpen() error {
+	if err := self.file.Close(); err != nil {
+		return fmt.Errorf("failed close %q: %w", self.filename, err)
+	}
+
+	return self.Open()
+}
+
+func (self *FileOutlet) Open() error {
+	f, err := os.OpenFile(self.filename, os.O_APPEND|os.O_CREATE|os.O_WRONLY, 0644)
+	if err != nil {
+		return fmt.Errorf("file outlet: %w", err)
+	}
+	self.file = f
+	self.writer = f
+
+	return nil
+}
+
+func (self *FileOutlet) ParseTemplate(templateText string) error {
+	funcMap := template.FuncMap{
+		"formatTime": func(t time.Time, layout string) string {
+			return t.Format(layout)
+		},
+	}
+
+	tmpl, err := template.New("").Funcs(funcMap).Parse(templateText)
+	if err != nil {
+		return fmt.Errorf("failed parse template %q: %w", templateText, err)
+	}
+	self.template = tmpl
+
+	return nil
+}
+
+func (self *FileOutlet) writeTemplate(t time.Time, msg string) error {
+	data := struct {
+		Time    time.Time
+		Pid     int
+		Message string
+	}{
+		Time:    t,
+		Pid:     os.Getpid(),
+		Message: msg,
+	}
+
+	if err := self.template.Execute(self.writer, data); err != nil {
+		return fmt.Errorf("failed execute template: %w", err)
+	}
+
+	if _, err := self.writer.Write([]byte("\n")); err != nil {
+		return fmt.Errorf("failed write to %q: %w", self.filename, err)
+	}
+
+	return nil
+}
+
+func (self *FileOutlet) writeBytes(bytes []byte) error {
+	if _, err := self.writer.Write(bytes); err != nil {
+		return fmt.Errorf("failed write to %q: %w", self.filename, err)
+	}
+
+	if _, err := self.writer.Write([]byte("\n")); err != nil {
+		return fmt.Errorf("failed write to %q: %w", self.filename, err)
+	}
 
+	return nil
 }
diff --git docs/configuration/filter_syntax.rst docs/configuration/filter_syntax.rst
index b18172f..2765a1b 100644
--- docs/configuration/filter_syntax.rst
+++ docs/configuration/filter_syntax.rst
@@ -15,8 +15,10 @@ The following rules determine which result is chosen for a given filesystem path
 * Non-wildcard patterns (full path patterns) win over *subtree wildcards* (`<` at end of pattern)
 * If the path in question does not match any pattern, the result is ``false``.
 
-The **subtree wildcard** ``<`` means "the dataset left of ``<`` and all its children".
-   
+The **subtree wildcard** ``<`` means "the dataset left of ``<`` and all its
+children". On the right of ``<`` can be added shell pattern, which filters
+children of the dataset.
+
 .. TIP::
   You can try out patterns for a configured job using the ``zrepl test filesystems`` subcommand for push and source jobs.
 
@@ -50,7 +52,8 @@ The following configuration demonstrates all rules presented above.
       filesystems: {
         "tank<": true,          # rule 1
         "tank/foo<": false,     # rule 2
-        "tank/foo/bar": true,  # rule 3
+        "tank/foo/bar": true,   # rule 3
+        "tank/bar</*/foo": true # rule 4
       }
       ...
 
@@ -64,4 +67,7 @@ Which rule applies to given path, and what is the result?
     tank/foo/bar     => 3    true
     zroot            => NONE false
     tank/var/log     => 1    true
-
+    tank/bar/a       => 4    false
+    tank/bar/a/foo   => 4    true
+    tank/bar/b       => 4    false
+    tank/bar/b/foo   => 4    true
diff --git docs/configuration/jobs.rst docs/configuration/jobs.rst
index 523e534..5b932ca 100644
--- docs/configuration/jobs.rst
+++ docs/configuration/jobs.rst
@@ -24,8 +24,13 @@ Job Type ``push``
       - |connect-transport|
     * - ``filesystems``
       - |filter-spec| for filesystems to be snapshotted and pushed to the sink
+    * - ``interval``
+      - | Interval at which to push to the sink (e.g. ``10m``) if
+        | ``snapshotting`` configured as ``manual``. This field is optional and
+        | if not defined, than ``snapshotting`` does the job. Also this field
+        | ignored if ``snapshotting`` isn't ``manual``.
     * - ``send``
-      - |send-options| 
+      - |send-options|
     * - ``snapshotting``
       - |snapshotting-spec|
     * - ``pruning``
diff --git docs/configuration/logging.rst docs/configuration/logging.rst
index aeed2ba..e57e787 100644
--- docs/configuration/logging.rst
+++ docs/configuration/logging.rst
@@ -106,6 +106,54 @@ Outlets
 
 Outlets are the destination for log entries.
 
+.. _logging-outlet-file:
+
+``file`` Outlet
+-----------------
+
+.. list-table::
+    :widths: 10 90
+    :header-rows: 1
+
+    * - Parameter
+      - Comment
+    * - ``type``
+      - ``file``
+    * - ``level``
+      -  minimum  :ref:`log level <logging-levels>`
+    * - ``format``
+      - output :ref:`format <logging-formats>`
+    * - ``time``
+      - always include time in output (``true`` or ``false``). Default is ``true``.
+    * - ``log_level``
+      - include log level into output (``true`` or ``false``). Default is ``true``.
+    * - ``filename``
+      - path of the log file
+    * - ``template``
+      - format output by Go template string
+
+Writes all log entries with minimum level ``level`` formatted by ``format`` to
+file from ``filename``. This outlet automatically detects the log file was
+rotated and reopens it.
+
+If ``template`` configured, log entries formatted by this template. For instance
+this configuration
+
+::
+
+    - type: "file"
+      level:  "info"
+      format: "human"
+      filename: "/var/log/zrepl.log"
+      time: false
+      template: '{{formatTime .Time "Jan _2 15:04:05"}} zrepl[{{.Pid}}]: {{.Message}}'
+
+formats log entries like ::
+
+  ``Oct 22 21:51:02 zrepl[29094]: [INFO][job-name][job][abcd$dcab$abcd.dcab]: wait for wakeups``.
+
+Can be specified many times with different ``filename``.
+
 .. _logging-outlet-stdout:
 
 ``stdout`` Outlet
diff --git pruning/keep_last_n.go pruning/keep_last_n.go
index 023568d..73f00cc 100644
--- pruning/keep_last_n.go
+++ pruning/keep_last_n.go
@@ -33,11 +33,6 @@ func NewKeepLastN(n int, regex string) (*KeepLastN, error) {
 }
 
 func (k KeepLastN) KeepRule(snaps []Snapshot) (destroyList []Snapshot) {
-
-	if k.n > len(snaps) {
-		return []Snapshot{}
-	}
-
 	matching, notMatching := partitionSnapList(snaps, func(snapshot Snapshot) bool {
 		return k.re.MatchString(snapshot.Name())
 	})
diff --git pruning/keep_last_n_test.go pruning/keep_last_n_test.go
index 4283e3e..17e7394 100644
--- pruning/keep_last_n_test.go
+++ pruning/keep_last_n_test.go
@@ -90,7 +90,7 @@ func TestKeepLastN(t *testing.T) {
 				stubSnap{"a2", false, o(12)},
 			},
 			rules: []KeepRule{
-				MustKeepLastN(3, "a"),
+				MustKeepLastN(4, "a"),
 			},
 			expDestroy: map[string]bool{
 				"b1": true,
